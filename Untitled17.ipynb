{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNex1ne7rv/hJKJIhLKf8DG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/morzahavi/corsound/blob/main/Untitled17.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gpu_info = !nvidia-smi\n",
        "# gpu_info = '\\n'.join(gpu_info)\n",
        "# if gpu_info.find('failed') >= 0:\n",
        "#   print('Not connected to a GPU')\n",
        "# else:\n",
        "#   print(gpu_info)"
      ],
      "metadata": {
        "id": "bqq2VUExE7P-"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from psutil import virtual_memory\n",
        "# ram_gb = virtual_memory().total / 1e9\n",
        "# print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "# if ram_gb < 20:\n",
        "#   print('Not using a high-RAM runtime')\n",
        "# else:\n",
        "#   print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "id": "6LAAHtlDFXI-"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "-OI7Ghbr6w6U"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Check if the extracted directory or file exists (replace 'dataset_directory_or_file_name' with the actual name)\n",
        "if not os.path.exists(\"dataset\"):\n",
        "    # Download the dataset\n",
        "    !gdown --id 1VSexRwiUJmcCyXw3KSEzFGxNhorngHq7\n",
        "\n",
        "    # Extract the dataset\n",
        "    !tar xf dataset_classification.tar\n",
        "\n",
        "    # Install the required library\n",
        "    !pip install transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "import datetime\n",
        "import pytz\n",
        "\n",
        "# Wandb import\n",
        "try:\n",
        "    import wandb\n",
        "except ImportError:\n",
        "    !pip install wandb\n",
        "\n",
        "# Constants\n",
        "IMG_SIZE = (224, 224)\n",
        "NORMALIZE_MEAN = (0.485, 0.456, 0.406)\n",
        "NORMALIZE_STD = (0.229, 0.224, 0.225)\n",
        "TIMEZONE = pytz.timezone('Asia/Jerusalem')\n",
        "CURRENT_TIME = datetime.datetime.now(TIMEZONE).strftime('%Y_%m_%d__%H_%M_%S')\n",
        "\n",
        "\n",
        "class CFG:\n",
        "    debug = True\n",
        "    subset = 1000\n",
        "    comment = \"\"\n",
        "    seed = 101\n",
        "    backbone = \"resnet101\"\n",
        "    batch_size = 8\n",
        "    epochs = 5\n",
        "    loss = \"binary_crossentropy\"\n",
        "    optimizer = \"Adam\"\n",
        "    lr = 1e-4\n",
        "    token_length = 100\n",
        "\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_length):\n",
        "        self.dataframe = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize(IMG_SIZE),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(NORMALIZE_MEAN, NORMALIZE_STD)\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.dataframe.iloc[idx]\n",
        "        image = Image.open(row[\"image\"]).convert(\"RGB\")\n",
        "        image = self.transform(image)\n",
        "        text = row[\"text\"]\n",
        "        inputs = self.tokenizer(text, return_tensors=\"pt\", max_length=self.max_length, padding=\"max_length\", truncation=True)\n",
        "        input_ids = inputs[\"input_ids\"].squeeze(0)\n",
        "        attention_mask = inputs[\"attention_mask\"].squeeze(0)\n",
        "        label = torch.tensor(row[\"label\"], dtype=torch.float32)\n",
        "        return image, input_ids, attention_mask, label\n",
        "\n",
        "class MultimodalClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MultimodalClassifier, self).__init__()\n",
        "        self.resnet = getattr(models, CFG.backbone)(pretrained=True)\n",
        "\n",
        "        # Get the in_features before replacing the fc layer with Identity\n",
        "        resnet_out_features = self.resnet.fc.in_features\n",
        "\n",
        "        self.resnet.fc = nn.Identity()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "        self.fc = nn.Linear(resnet_out_features + self.bert.config.hidden_size, 1)\n",
        "\n",
        "    def forward(self, image, input_ids, attention_mask):\n",
        "        image_embed = self.resnet(image)\n",
        "        text_embed = self.bert(input_ids=input_ids, attention_mask=attention_mask).pooler_output\n",
        "        combined = torch.cat([image_embed, text_embed], dim=1)\n",
        "        output = self.fc(combined)\n",
        "        return output.squeeze()\n",
        "\n",
        "# Class Weights\n",
        "class_counts = train_data[\"label\"].value_counts().to_dict()\n",
        "\n",
        "# For binary classification:\n",
        "num_negative = class_counts[0]\n",
        "num_positive = class_counts[1]\n",
        "\n",
        "total = num_negative + num_positive\n",
        "\n",
        "weight_for_0 = (1 / num_negative) * (total) / 2.0\n",
        "weight_for_1 = (1 / num_positive) * (total) / 2.0\n",
        "\n",
        "class_weights = {0: weight_for_0, 1: weight_for_1}\n",
        "print(class_weights)\n",
        "\n",
        "#\n",
        "def load_data():\n",
        "    data_path = \"dataset/dataset.parquet\"\n",
        "    data = pd.read_parquet(data_path)\n",
        "    if CFG.debug:\n",
        "        data = data.sample(CFG.subset)\n",
        "    return train_test_split(data, test_size=0.2, random_state=CFG.seed)\n",
        "\n",
        "\n",
        "def evaluate(model, dataloader):\n",
        "    model.eval()\n",
        "    all_labels, all_preds = [], []\n",
        "    with torch.no_grad():\n",
        "        for items in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "            image, input_ids, attention_mask, label = (item.to(device) for item in items)\n",
        "            output = model(image, input_ids, attention_mask)\n",
        "            preds = (torch.sigmoid(output) > 0.5).int().cpu().numpy()  # Applying sigmoid before thresholding\n",
        "            all_preds.extend(preds)\n",
        "            all_labels.extend(label.cpu().int().numpy())\n",
        "    return all_labels, all_preds\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    cfg_instance = CFG()\n",
        "    wandb.init(project='caption_prediction', name=CURRENT_TIME, config=vars(cfg_instance))\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    train_data, val_data = load_data()\n",
        "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "    train_dataset = CustomDataset(train_data, tokenizer, CFG.token_length)\n",
        "    val_dataset = CustomDataset(val_data, tokenizer, CFG.token_length)\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "    model = MultimodalClassifier().to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=CFG.lr)\n",
        "    weights = torch.tensor([class_weights[0], class_weights[1]]).to(device)\n",
        "    loss_fn = nn.BCEWithLogitsLoss(pos_weight=weights[1])\n",
        "    scheduler = OneCycleLR(optimizer, max_lr=1e-3, epochs=CFG.epochs, steps_per_epoch=len(train_dataloader))\n",
        "    wandb.watch(model, log='all')\n",
        "\n",
        "    for epoch in range(CFG.epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for items in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{CFG.epochs}\"):\n",
        "            image, input_ids, attention_mask, label = (item.to(device) for item in items)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(image, input_ids, attention_mask)\n",
        "            loss = loss_fn(output, label)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            total_loss += loss.item()\n",
        "        wandb.log({\"Train Loss\": total_loss/len(train_dataloader)}, step=epoch)\n",
        "        labels, preds = evaluate(model, val_dataloader)\n",
        "        metrics = {\n",
        "            \"Accuracy\": accuracy_score(labels, preds),\n",
        "            \"Precision\": precision_score(labels, preds),\n",
        "            \"Recall\": recall_score(labels, preds),\n",
        "            \"F1 Score\": f1_score(labels, preds),\n",
        "        }\n",
        "        print(metrics)\n",
        "        wandb.log(metrics, step=epoch)\n",
        "\n",
        "    torch.save(model.state_dict(), 'model.pth')\n",
        "    wandb.save('model.pth')\n",
        "    wandb.finish()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 779
        },
        "id": "4Bco31Z87a5Q",
        "outputId": "287b7cae-a5be-454c-b4dc-ae771e9dcfd9"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 0.5847953216374269, 1: 3.4482758620689653}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230821_154529-koub3dbh</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/morzzz/caption_prediction/runs/koub3dbh' target=\"_blank\">2023_08_21__18_45_29</a></strong> to <a href='https://wandb.ai/morzzz/caption_prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/morzzz/caption_prediction' target=\"_blank\">https://wandb.ai/morzzz/caption_prediction</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/morzzz/caption_prediction/runs/koub3dbh' target=\"_blank\">https://wandb.ai/morzzz/caption_prediction/runs/koub3dbh</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Epoch 1/5: 100%|██████████| 100/100 [00:32<00:00,  3.06it/s]\n",
            "Evaluating: 100%|██████████| 25/25 [00:02<00:00,  8.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Accuracy': 0.195, 'Precision': 0.18781725888324874, 'Recall': 0.9736842105263158, 'F1 Score': 0.31489361702127666}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 100%|██████████| 100/100 [00:33<00:00,  2.95it/s]\n",
            "Evaluating: 100%|██████████| 25/25 [00:02<00:00,  8.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Accuracy': 0.79, 'Precision': 0.0, 'Recall': 0.0, 'F1 Score': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 100%|██████████| 100/100 [00:33<00:00,  3.01it/s]\n",
            "Evaluating: 100%|██████████| 25/25 [00:02<00:00,  9.11it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Accuracy': 0.81, 'Precision': 0.0, 'Recall': 0.0, 'F1 Score': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 100%|██████████| 100/100 [00:33<00:00,  3.00it/s]\n",
            "Evaluating: 100%|██████████| 25/25 [00:02<00:00,  8.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Accuracy': 0.805, 'Precision': 0.3333333333333333, 'Recall': 0.02631578947368421, 'F1 Score': 0.048780487804878044}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 100%|██████████| 100/100 [00:33<00:00,  2.99it/s]\n",
            "Evaluating: 100%|██████████| 25/25 [00:02<00:00,  8.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Accuracy': 0.8, 'Precision': 0.25, 'Recall': 0.02631578947368421, 'F1 Score': 0.04761904761904762}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>▁████</td></tr><tr><td>F1 Score</td><td>█▁▁▂▂</td></tr><tr><td>Precision</td><td>▅▁▁█▆</td></tr><tr><td>Recall</td><td>█▁▁▁▁</td></tr><tr><td>Train Loss</td><td>▇█▅▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>0.8</td></tr><tr><td>F1 Score</td><td>0.04762</td></tr><tr><td>Precision</td><td>0.25</td></tr><tr><td>Recall</td><td>0.02632</td></tr><tr><td>Train Loss</td><td>0.92847</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">2023_08_21__18_45_29</strong> at: <a href='https://wandb.ai/morzzz/caption_prediction/runs/koub3dbh' target=\"_blank\">https://wandb.ai/morzzz/caption_prediction/runs/koub3dbh</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230821_154529-koub3dbh/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(f\"TN: {tn}, TP: {tp}, FN: {fn}, FP: {fp}\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall (Sensitivity): {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(f\"Specificity: {specificity:.4f}\")\n",
        "print(f\"False Positive Rate: {fpr:.4f}\")\n",
        "print(f\"Negative Predictive Value: {npv:.4f}\")\n",
        "\n",
        "# Inference function\n",
        "def predict(image_path, caption):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        image = train_dataset.transform(image).unsqueeze(0).to(device)\n",
        "        inputs = tokenizer(caption, return_tensors=\"pt\", max_length=32, padding=\"max_length\", truncation=True)\n",
        "        input_ids = inputs[\"input_ids\"].to(device)\n",
        "        attention_mask = inputs[\"attention_mask\"].to(device)\n",
        "        output = model(image, input_ids, attention_mask)\n",
        "        pred = (output > 0.5).item()\n",
        "    return \"Positive\" if pred == 1 else \"Negative\"\n",
        "\n",
        "# Test the inference function\n",
        "print(predict(\"dataset/images/00002/000025708.jpg\", \"A group of people flying a large colorful kite in winter.\"))\n",
        "\n",
        "print(f\"Number of images/samples being used: {len(data)}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y35f0y5PsOE8",
        "outputId": "9a0f8246-dff7-4290-d27b-db9ddbeea6fa"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TN: 168, TP: 0, FN: 32, FP: 0\n",
            "Accuracy: 0.8400\n",
            "Precision: 0.0000\n",
            "Recall (Sensitivity): 0.0000\n",
            "F1-Score: 0.0000\n",
            "Specificity: 1.0000\n",
            "False Positive Rate: 0.0000\n",
            "Negative Predictive Value: 0.8400\n",
            "Negative\n",
            "Number of images/samples being used: 2000\n"
          ]
        }
      ]
    }
  ]
}